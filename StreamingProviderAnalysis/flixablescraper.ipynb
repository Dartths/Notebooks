{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5GdG6xE-ZNN"
      },
      "source": [
        "# Scraping of Fixable.com\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "74nreExY-vjC"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "service_paths = [\"\",\"amazon-prime-video/\",\"disney-plus/\",\"hbo-max/\",\"hulu/\" ]\n",
        "base_url = \"https://flixable.com/\"\n",
        "paths = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "CX5QXTqg_mta"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n"
          ]
        }
      ],
      "source": [
        "for service_path in service_paths:\n",
        "    page = 1\n",
        "    a = True\n",
        "    while True:\n",
        "        query = '?min-rating=0&min-year=1920&max-year=2022&order=date&page='\n",
        "        response = requests.get(base_url + service_path + query + str(page))\n",
        "        html = response.content\n",
        "        soup = BeautifulSoup(html, 'html') \n",
        "        response_html = soup.find_all(\"div\", {\"id\": \"response\"})[0]\n",
        "        cards = response_html.findAll(\"div\", {\"class\": \"card-body\"})\n",
        "        if len(cards) > 1:\n",
        "            page += 1\n",
        "            print(page)\n",
        "            for card in cards:\n",
        "               paths.append(card.findAll('a', href=True)[0]['href'])\n",
        "        else: \n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Have all the paths, now get all the content, lets write the paths somewhere first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=pd.DataFrame(paths, columns=['path']) \n",
        "df.to_csv(\"C:\\\\DCUGoogleDrive\\\\DataVisualisationScrapedData.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The initial paths are grabbed, from there I need to do 1 main thing, loop through each row, attach it the path to the base url, query, then extract the data from the result\n",
        "So hopefully the data is nicely formed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "months = {\n",
        "\"January\": \"1\",\n",
        "\"February\": \"2\",\n",
        "\"March\":\"3\",\n",
        "\"April\":\"4\",\n",
        "\"May\": \"5\",\n",
        "\"June\":\"6\",\n",
        "\"July\":\"7\",\n",
        "\"August\":\"8\",\n",
        "\"September\":\"9\",\n",
        "\"October\":\"10\",\n",
        "\"November\": \"11\",\n",
        "\"December\": \"12\"\n",
        "}\n",
        "\n",
        "def remove_special_characters(title):\n",
        "    new_text = ''\n",
        "    for character in title:\n",
        "        if character == ' ':\n",
        "            new_text += '-'\n",
        "        elif character.isalnum():\n",
        "            new_text += character\n",
        "    return new_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_date(soup):\n",
        "    x = soup.find('p', {'class':'mb-2'})\n",
        "    if x is None:\n",
        "        return '' \n",
        "    else :\n",
        "        x = x.find_all('span')\n",
        "        if len(x) < 2:\n",
        "            return ''\n",
        "        else :\n",
        "            x = x[1].get_text().replace(',', '').split(' ')\n",
        "            if len(x) < 3:\n",
        "                return ''\n",
        "            else :\n",
        "                return x[2] + '-'+ months[x[0]] + '-' + x[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_title(soup):\n",
        "    return soup.find('h1', {'class' : 'title'}).get_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_soup(path):\n",
        "    response = requests.get(path)\n",
        "    return BeautifulSoup(response.content, 'html') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_source(path):\n",
        "    arr = path.split('/')\n",
        "    if arr[1] =='title':\n",
        "        return 'netflix'\n",
        "    else:\n",
        "        return arr[1]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'amazon-prime-video'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_source('/amazon-prime-video/title/baby-ronnie-rhymes/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_sib_by_text(soup, el, text):\n",
        "    x = soup.find(\"span\", text=text)\n",
        "    if x is None:\n",
        "        return ''\n",
        "    else:\n",
        "        return x.next_sibling.get_text()\n",
        "\n",
        "def get_director(soup):\n",
        "    return get_sib_by_text(soup, \"span\", \"Director:\")\n",
        "\n",
        "def get_genres(soup):\n",
        "    return get_sib_by_text(soup, \"span\", \"Genres:\")\n",
        "\n",
        "def get_cast(soup):\n",
        "    return get_sib_by_text(soup, \"span\", \"Cast:\")\n",
        "\n",
        "def get_production_country(soup):\n",
        "    return get_sib_by_text(soup, \"span\", \"Production Country:\")\n",
        "\n",
        "def get_rating(soup):\n",
        "    x = soup.find(\"h6\", {\"class\": \"card-category\"})   \n",
        "    if x is None:\n",
        "        return ''\n",
        "    else:\n",
        "        x = x.find(\"span\", {\"class\": \"fas fa-star rating mr-1\"})\n",
        "        if x is None:\n",
        "            return '' \n",
        "        else :\n",
        "            return x.next_sibling.get_text()\n",
        "\n",
        "def get_duration(soup):\n",
        "    x = soup.find(\"h6\", {\"class\": \"card-category\"})\n",
        "    if x is None:\n",
        "        return ''\n",
        "    else:\n",
        "        x = x.find_all(\"span\")\n",
        "        if x is None:\n",
        "            return ''\n",
        "        else:\n",
        "            if len(x) > 2:\n",
        "                return x[2].get_text()\n",
        "            else :\n",
        "                return ''\n",
        "\n",
        "def get_audience(soup):\n",
        "    x = soup.find(\"h6\", {\"class\": \"card-category\"}).find_all(\"span\")[1]   \n",
        "    if x is None:\n",
        "        return ''\n",
        "    else:\n",
        "        return x.get_text()\n",
        "\n",
        "def get_type(soup):\n",
        "    if 'Season' in get_duration(soup):\n",
        "        return 'tv-show'\n",
        "    else:\n",
        "        return 'movie'\n",
        "\n",
        "def get_release_year(soup):\n",
        "    x = soup.find('span', {'class' : 'mr-2'})\n",
        "    if x is None:\n",
        "        return ''\n",
        "    else:\n",
        "        return x.get_text()\n",
        "\n",
        "def get_description(soup):\n",
        "    x = soup.find('p', {'class' : 'card-description'})\n",
        "    if x is None:\n",
        "        return ''\n",
        "    else:\n",
        "        return x.get_text()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "scrapedFrame = pd.read_csv(\"C:\\\\DCUGoogleDrive\\\\DataVisualisationScrapedFinal.csv\")\n",
        "df = pd.read_csv(\"C:\\\\DCUGoogleDrive\\\\DataVisualisationScrapedData.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "default_Titles = ['Full List of Movies and TV Shows on Amazon Prime Video | Flixable',\n",
        "'Full List of Movies and TV Shows on Netflix | Flixable',\n",
        "'Full List of Movies and Series on Disney+ | Flixable',\n",
        "'Full List of Movies and Series on HBO Max | Flixable',\n",
        "'Full List of Movies and TV Shows on Hulu | Flixable',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving at row 20100\n",
            "Saving at row 20200\n",
            "Saving at row 20300\n",
            "Saving at row 20400\n",
            "Saving at row 20500\n",
            "Saving at row 20600\n",
            "Saving at row 20700\n",
            "Saving at row 20800\n",
            "Saving at row 20900\n",
            "Saving at row 21000\n",
            "Saving at row 21100\n",
            "Saving at row 21200\n",
            "Saving at row 21300\n",
            "Saving at row 21400\n",
            "Saving at row 21500\n",
            "Saving at row 21600\n",
            "Saving at row 21700\n",
            "Saving at row 21800\n",
            "Saving at row 21900\n",
            "Saving at row 22000\n",
            "Saving at row 22100\n",
            "Saving at row 22200\n",
            "Saving at row 22300\n",
            "Saving at row 22400\n",
            "Saving at row 22500\n",
            "Saving at row 22600\n",
            "Saving at row 22700\n",
            "Saving at row 22800\n",
            "Saving at row 22900\n",
            "Saving at row 23000\n",
            "Saving at row 23100\n",
            "Saving at row 23200\n",
            "Saving at row 23300\n",
            "Saving at row 23400\n",
            "Saving at row 23500\n",
            "Saving at row 23600\n",
            "Saving at row 23700\n",
            "Saving at row 23800\n",
            "Saving at row 23900\n",
            "Saving at row 24000\n",
            "Saving at row 24100\n",
            "Saving at row 24200\n",
            "skipping /hulu/title/the-cup/\n",
            "Saving at row 24300\n",
            "Saving at row 24400\n",
            "Saving at row 24500\n",
            "Saving at row 24600\n",
            "Saving at row 24700\n",
            "Saving at row 24800\n",
            "Saving at row 24900\n",
            "Saving at row 25000\n",
            "Saving at row 25100\n",
            "skipping /hulu/title/ninas-world/\n",
            "Saving at row 25200\n",
            "Saving at row 25300\n",
            "Saving at row 25400\n",
            "Saving at row 25500\n",
            "Saving at row 25600\n",
            "Saving at row 25700\n",
            "Saving at row 25800\n"
          ]
        }
      ],
      "source": [
        "#scrapedFrame = pd.DataFrame(columns = ['source', 'title', 'type', 'director', 'cast', 'production_countries', 'date_added','release_year', 'rating', 'duration', 'genres', 'description'])\n",
        "scraped_rows = []\n",
        "start_pos = len(scrapedFrame) + 1\n",
        "for idx, row in df.iterrows():\n",
        "    if idx > start_pos:\n",
        "        soup = get_soup(base_url + row['path'])\n",
        "        if soup.find('title').get_text() in default_Titles:\n",
        "            print('skipping ' + row['path'])\n",
        "        else:\n",
        "            new_row = {\n",
        "            'source':get_source(row['path'])\n",
        "            ,'title':get_title(soup)\n",
        "            ,'type':get_type(soup)\n",
        "            ,'director':get_director(soup)\n",
        "            ,'cast':get_cast(soup)\n",
        "            ,'production_countries':get_production_country(soup)\n",
        "            ,'date_added':get_date(soup)\n",
        "            ,'release_year':get_release_year(soup)\n",
        "            ,'rating': get_rating(soup)\n",
        "            ,'audience' : get_audience(soup)\n",
        "            ,'duration':get_duration(soup)\n",
        "            ,'genres':get_genres(soup)\n",
        "            ,'description':get_description(soup)}\n",
        "            scraped_rows.append(new_row)\n",
        "           # print(new_row)\n",
        "        if idx % 100 == 0:\n",
        "            print('Saving at row ' + str(idx))\n",
        "            scrapedFrame = scrapedFrame.append(scraped_rows, ignore_index=True)\n",
        "            scrapedFrame.to_csv(\"C:\\\\DCUGoogleDrive\\\\DataVisualisationScrapedFinal.csv\")\n",
        "            scraped_rows = []\n",
        "\n",
        "\n",
        "scrapedFrame = scrapedFrame.append(scraped_rows, ignore_index=True)\n",
        "scrapedFrame.to_csv(\"C:\\\\DCUGoogleDrive\\\\DataVisualisationScrapedFinal.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Full List of Movies and TV Shows on Hulu | Flixable'"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "soup = get_soup('https://flixable.com/hulu/')\n",
        "soup.find('title').get_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50 entries, 0 to 49\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   source                50 non-null     object\n",
            " 1   title                 50 non-null     object\n",
            " 2   type                  50 non-null     object\n",
            " 3   director              50 non-null     object\n",
            " 4   cast                  50 non-null     object\n",
            " 5   production_countries  50 non-null     object\n",
            " 6   date_added            50 non-null     object\n",
            " 7   release_year          50 non-null     object\n",
            " 8   rating                50 non-null     object\n",
            " 9   audience              50 non-null     object\n",
            " 10  duration              50 non-null     object\n",
            " 11  genres                50 non-null     object\n",
            " 12  description           50 non-null     object\n",
            "dtypes: object(13)\n",
            "memory usage: 5.2+ KB\n"
          ]
        }
      ],
      "source": [
        "scrapedFrame.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "2.4.8 Web Scraping.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "interpreter": {
      "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
